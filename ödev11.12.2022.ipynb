{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIUetmKZ/kiSgqk/H5YZGW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berkay86/DeepPerson/blob/main/%C3%B6dev11.12.2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Kütüphanelerimizi içeriye alalım.\n",
        "#Veri İşlemleri\n",
        "!pip3 install snscrape\n",
        "import pandas as pd\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCjnG1zdyi5p",
        "outputId": "0acd5457-583a-4ea7-9ae9-233cf267f580"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.8/dist-packages (0.4.3.20220106)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from snscrape) (3.8.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from snscrape) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from snscrape) (2022.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.9.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer \n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib import rcParams\n",
        "from collections import Counter\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "import string\n",
        "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "-o5As_kNFEP3"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import string\n"
      ],
      "metadata": {
        "id": "MvWLrSbF0FsC"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "import textblob\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "QMm0Xcmk0G15"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud.wordcloud import WordCloud,STOPWORDS\n",
        "!pip install emot\n",
        "from emot.emo_unicode import UNICODE_EMOJI\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "from wordcloud import ImageColorGenerator\n",
        "from PIL import Image\n",
        "import warnings\n",
        "%matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qbIECSI0Hpi",
        "outputId": "2afc6e23-f356-4529-c0b6-a3af256a5b23"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emot in /usr/local/lib/python3.8/dist-packages (3.1)\n",
            "Using matplotlib backend: agg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"(Reviews AND Resturant )\"\n",
        "tweets=[]\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
        "  if i>2000:\n",
        "    break\n",
        "  else:\n",
        "        tweets.append([tweet.date,tweet.id,tweet.url,tweet.user.username,tweet.sourceLabel,tweet.user.location,tweet.content,tweet.likeCount,tweet.retweetCount])\n",
        "df=pd.DataFrame(tweets,columns=[\"Date\",\"ID\",\"url\",\"username\",\"source\",\"location\",\"tweet\",\"num_of_likes\", \"num_of_retweet\"])\n"
      ],
      "metadata": {
        "id": "4nbgfT_r0LNp"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "turk_stop_words=list(stopwords.words(\"english\"))\n",
        "emoji=list(UNICODE_EMOJI.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYVbOtFY0NAD",
        "outputId": "ffa3a4cf-cffd-4a32-bde1-0d33732f341b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"location\"]=df[\"location\"].fillna(\"Unknown\")"
      ],
      "metadata": {
        "id": "eNl44yMO0PgQ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Polarity\"]=df[\"Processed_Tweets\"].apply(polarity)\n",
        "df[\"Sentiment\"]=df[\"Polarity\"].apply(sentimenttextblob)\n",
        "sent=df[\"Sentiment\"].value_counts()\n",
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "S3rAeINk0g5k",
        "outputId": "af14707d-7436-43af-8d31-8e73fb1ff329"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-425642b40d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Polarity\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Processed_Tweets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Polarity\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentimenttextblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-187-1011f155df5f>\u001b[0m in \u001b[0;36mpolarity\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msentimenttextblob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/textblob/blob.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, tokenizer, pos_tagger, np_extractor, analyzer, parser, classifier, clean_html)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 parser=None, classifier=None, clean_html=False):\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             raise TypeError('The `text` argument passed to `__init__(text)` '\n\u001b[0m\u001b[1;32m    370\u001b[0m                             'must be a string, not {0}'.format(type(text)))\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclean_html\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: The `text` argument passed to `__init__(text)` must be a string, not <class 'float'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def polarity(tweet):\n",
        "  return TextBlob(tweet).sentiment.polarity\n",
        "def sentimenttextblob(polarity):\n",
        "  if polarity<0:\n",
        "    return 2\n",
        "  elif polarity==0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n"
      ],
      "metadata": {
        "id": "f-WbF2m29jXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Polarity\"]"
      ],
      "metadata": {
        "id": "TSlBeDCC9q2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ProcessedTweets(text):\n",
        "  text=text.lower()\n",
        "  text=\" \".join(re.sub(\"(@[A-Za-z0-9]+)|(^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\",\" \",text).split()) \n",
        "  text=re.sub(r'\\@\\w+|\\#\\w+|\\d+', \"\", text)\n",
        "  punct=str.maketrans(\"\",\"\",string.punctuation+string.digits)\n",
        "  text=text.translate(punct)\n",
        "  tokens=word_tokenize(text)\n",
        "  filtered_words=[w for w in tokens if w not in turk_stop_words]\n",
        "  filtered_words=[w for w in filtered_words if w not in emoji]\n",
        "  lemmatizer=WordNetLemmatizer()\n",
        "  lemma_words=[lemmatizer.lemmatize(w) for w in filtered_words]\n",
        "  text=\" \".join(lemma_words)\n",
        "  return text\n",
        "df.to_csv(\"sentiment.csv\",encoding=\"utf-8\")\n",
        "df\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "df[\"Processed_Tweets\"]=df[\"tweet\"].apply(ProcessedTweets)\n"
      ],
      "metadata": {
        "id": "dnQNVkim0Qrk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "13a8acdb-23a5-44ae-97f0-a5bbb6bf2700"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Date                   ID  \\\n",
              "0    2022-12-09 23:45:14+00:00  1601362364276019200   \n",
              "1    2022-12-05 04:19:40+00:00  1599619490148675584   \n",
              "2    2022-12-04 15:00:50+00:00  1599418455262121986   \n",
              "3    2022-11-28 18:58:45+00:00  1597304005088010240   \n",
              "4    2022-11-26 11:49:59+00:00  1596471325379694592   \n",
              "...                        ...                  ...   \n",
              "1996 2012-03-31 12:55:26+00:00   186074221657587712   \n",
              "1997 2012-03-28 06:02:00+00:00   184883013916696576   \n",
              "1998 2012-03-27 17:18:15+00:00   184690811651362818   \n",
              "1999 2012-03-27 16:47:11+00:00   184682991568683009   \n",
              "2000 2012-03-27 08:01:17+00:00   184550647855726592   \n",
              "\n",
              "                                                    url         username  \\\n",
              "0     https://twitter.com/twinskincabins/status/1601...   twinskincabins   \n",
              "1     https://twitter.com/RashadButler20/status/1599...   RashadButler20   \n",
              "2     https://twitter.com/_Sourabhmehta/status/15994...    _Sourabhmehta   \n",
              "3     https://twitter.com/ChardineTaylor/status/1597...   ChardineTaylor   \n",
              "4     https://twitter.com/Rudy_phenomenol/status/159...  Rudy_phenomenol   \n",
              "...                                                 ...              ...   \n",
              "1996  https://twitter.com/Botamba/status/18607422165...          Botamba   \n",
              "1997  https://twitter.com/SDot_93/status/18488301391...          SDot_93   \n",
              "1998  https://twitter.com/farmvillevip/status/184690...     farmvillevip   \n",
              "1999  https://twitter.com/jennym210/status/184682991...        jennym210   \n",
              "2000  https://twitter.com/farmvillevip/status/184550...     farmvillevip   \n",
              "\n",
              "                   source        location  \\\n",
              "0      Twitter for iPhone                   \n",
              "1      Twitter for iPhone         Youtube   \n",
              "2         Twitter Web App       Bengaluru   \n",
              "3         Twitter Web App  United Kingdom   \n",
              "4     Twitter for Android  Chennai, India   \n",
              "...                   ...             ...   \n",
              "1996              Botamba          Kuwait   \n",
              "1997   Twitter Web Client                   \n",
              "1998          twitterfeed                   \n",
              "1999          twitterfeed   new york, USA   \n",
              "2000          twitterfeed                   \n",
              "\n",
              "                                                  tweet  num_of_likes  \\\n",
              "0     TrustPilot Review! Best Resturant in Mancheste...             0   \n",
              "1     Check out my review of The Menu. \\nhttps://t.c...             0   \n",
              "2     @zomatocare @zomato would you care to explain ...             1   \n",
              "3     Oh look it's the Guardian with ANOTHER article...            61   \n",
              "4     most of the hits that come up in google have f...             4   \n",
              "...                                                 ...           ...   \n",
              "1996  Review: Locanda Resturant: مطعم جديد مكانه بال...             3   \n",
              "1997  I only have 2 dream jobs being a Weed conoscer...             0   \n",
              "1998  farmville - loss of farm cash/floating restura...             0   \n",
              "1999  farmville - loss of farm cash/floating restura...             0   \n",
              "2000  farmville - loss of farm cash/floating restura...             0   \n",
              "\n",
              "      num_of_retweet  \n",
              "0                  0  \n",
              "1                  0  \n",
              "2                  0  \n",
              "3                  3  \n",
              "4                  0  \n",
              "...              ...  \n",
              "1996               1  \n",
              "1997               0  \n",
              "1998               0  \n",
              "1999               0  \n",
              "2000               0  \n",
              "\n",
              "[2001 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bdb60d7-5f35-4fb9-930b-d19e91a9003e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>ID</th>\n",
              "      <th>url</th>\n",
              "      <th>username</th>\n",
              "      <th>source</th>\n",
              "      <th>location</th>\n",
              "      <th>tweet</th>\n",
              "      <th>num_of_likes</th>\n",
              "      <th>num_of_retweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-12-09 23:45:14+00:00</td>\n",
              "      <td>1601362364276019200</td>\n",
              "      <td>https://twitter.com/twinskincabins/status/1601...</td>\n",
              "      <td>twinskincabins</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td></td>\n",
              "      <td>TrustPilot Review! Best Resturant in Mancheste...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-12-05 04:19:40+00:00</td>\n",
              "      <td>1599619490148675584</td>\n",
              "      <td>https://twitter.com/RashadButler20/status/1599...</td>\n",
              "      <td>RashadButler20</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Youtube</td>\n",
              "      <td>Check out my review of The Menu. \\nhttps://t.c...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-12-04 15:00:50+00:00</td>\n",
              "      <td>1599418455262121986</td>\n",
              "      <td>https://twitter.com/_Sourabhmehta/status/15994...</td>\n",
              "      <td>_Sourabhmehta</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Bengaluru</td>\n",
              "      <td>@zomatocare @zomato would you care to explain ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-11-28 18:58:45+00:00</td>\n",
              "      <td>1597304005088010240</td>\n",
              "      <td>https://twitter.com/ChardineTaylor/status/1597...</td>\n",
              "      <td>ChardineTaylor</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Oh look it's the Guardian with ANOTHER article...</td>\n",
              "      <td>61</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-11-26 11:49:59+00:00</td>\n",
              "      <td>1596471325379694592</td>\n",
              "      <td>https://twitter.com/Rudy_phenomenol/status/159...</td>\n",
              "      <td>Rudy_phenomenol</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>Chennai, India</td>\n",
              "      <td>most of the hits that come up in google have f...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>2012-03-31 12:55:26+00:00</td>\n",
              "      <td>186074221657587712</td>\n",
              "      <td>https://twitter.com/Botamba/status/18607422165...</td>\n",
              "      <td>Botamba</td>\n",
              "      <td>Botamba</td>\n",
              "      <td>Kuwait</td>\n",
              "      <td>Review: Locanda Resturant: مطعم جديد مكانه بال...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>2012-03-28 06:02:00+00:00</td>\n",
              "      <td>184883013916696576</td>\n",
              "      <td>https://twitter.com/SDot_93/status/18488301391...</td>\n",
              "      <td>SDot_93</td>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td></td>\n",
              "      <td>I only have 2 dream jobs being a Weed conoscer...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>2012-03-27 17:18:15+00:00</td>\n",
              "      <td>184690811651362818</td>\n",
              "      <td>https://twitter.com/farmvillevip/status/184690...</td>\n",
              "      <td>farmvillevip</td>\n",
              "      <td>twitterfeed</td>\n",
              "      <td></td>\n",
              "      <td>farmville - loss of farm cash/floating restura...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>2012-03-27 16:47:11+00:00</td>\n",
              "      <td>184682991568683009</td>\n",
              "      <td>https://twitter.com/jennym210/status/184682991...</td>\n",
              "      <td>jennym210</td>\n",
              "      <td>twitterfeed</td>\n",
              "      <td>new york, USA</td>\n",
              "      <td>farmville - loss of farm cash/floating restura...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>2012-03-27 08:01:17+00:00</td>\n",
              "      <td>184550647855726592</td>\n",
              "      <td>https://twitter.com/farmvillevip/status/184550...</td>\n",
              "      <td>farmvillevip</td>\n",
              "      <td>twitterfeed</td>\n",
              "      <td></td>\n",
              "      <td>farmville - loss of farm cash/floating restura...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2001 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bdb60d7-5f35-4fb9-930b-d19e91a9003e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bdb60d7-5f35-4fb9-930b-d19e91a9003e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bdb60d7-5f35-4fb9-930b-d19e91a9003e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel(\"Book1.xlsx\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "u1vF9m007H9L",
        "outputId": "23a267f2-5387-4068-c8b9-1a0a7a917c31"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  label\n",
              "0                             Wow... Loved this place.      1\n",
              "1                                   Crust is not good.      0\n",
              "2            Not tasty and the texture was just nasty.      0\n",
              "3    Stopped by during the late May bank holiday of...      1\n",
              "4    The selection on the menu was great and so wer...      1\n",
              "..                                                 ...    ...\n",
              "995  I think food should have flavor and texture an...      0\n",
              "996                           Appetite instantly gone.      0\n",
              "997  Overall I was not impressed and would not go b...      0\n",
              "998  The whole experience was underwhelming, and I ...      0\n",
              "999  Then, as if I hadn't wasted enough of my life ...      0\n",
              "\n",
              "[1000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02358f71-ba0a-46b0-a457-ce5a7d2c2846\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The whole experience was underwhelming, and I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02358f71-ba0a-46b0-a457-ce5a7d2c2846')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02358f71-ba0a-46b0-a457-ce5a7d2c2846 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02358f71-ba0a-46b0-a457-ce5a7d2c2846');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "df[\"Processed_Tweets\"]=df[\"text\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APQa8G2-0a-o",
        "outputId": "3833c168-46da-4bdb-daa4-64eb079b8121"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pos = df[df['label']==1]\n",
        "data_neg = df[df['label']==0]"
      ],
      "metadata": {
        "id": "2dkn4aBDCiI_"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pos = data_pos.iloc[:int(2000)]\n",
        "data_neg = data_neg.iloc[:int(2000)]"
      ],
      "metadata": {
        "id": "lxbLKCxCDfNr"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([data_pos, data_neg])"
      ],
      "metadata": {
        "id": "VuNXaGRfDiYO"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Processed_Tweets\"]=df[\"Processed_Tweets\"].str.lower()\n"
      ],
      "metadata": {
        "id": "5TK1evWnDjda"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Processed_Tweets\"].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2LTKi5CDscJ",
        "outputId": "b12ddbc1-71b4-47f2-bf7f-87040b877071"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "995    i think food should have flavor and texture an...\n",
              "996                             appetite instantly gone.\n",
              "997    overall i was not impressed and would not go b...\n",
              "998    the whole experience was underwhelming, and i ...\n",
              "999    then, as if i hadn't wasted enough of my life ...\n",
              "Name: Processed_Tweets, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_list = stopwords.words('english')"
      ],
      "metadata": {
        "id": "bcImD94JDyTn"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\", \".join(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "SMLRQqeZDz10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "bfaaad1f-c8d8-4bcb-a8c5-61baac6b084c"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def cleaning_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "df[\"Processed_Tweets\"] = df[\"Processed_Tweets\"].apply(lambda text: cleaning_stopwords(text))\n",
        "df[\"Processed_Tweets\"].head()\n",
        "\n",
        "english_punctuations = string.punctuation\n",
        "punctuations_list = english_punctuations\n",
        "def cleaning_punctuations(text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return text.translate(translator)\n",
        "\n",
        "def cleaning_repeating_char(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
        "\n",
        "\n",
        "\n",
        "def cleaning_email(data):\n",
        "    return re.sub('@[^\\s]+', ' ', data)\n",
        "\n",
        "def cleaning_URLs(data):\n",
        "    return re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',data)\n",
        "\n",
        "\n",
        "def cleaning_numbers(data):\n",
        "    return re.sub('[0-9]+', '', data)\n",
        "\n",
        "\n",
        "\n",
        "st = nltk.PorterStemmer()\n",
        "def stemming_on_text(data):\n",
        "    text = [st.stem(word) for word in data]\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "lm = nltk.WordNetLemmatizer()\n",
        "def lemmatizer_on_text(data):\n",
        "    text = [lm.lemmatize(word) for word in data]\n",
        "    return data\n",
        "\n"
      ],
      "metadata": {
        "id": "HO1n5EsJD2Y2"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Processed_Tweets\"] = df[\"Processed_Tweets\"] .apply(lambda x: cleaning_punctuations(x))\n",
        "df[\"Processed_Tweets\"]  =df[\"Processed_Tweets\"].apply(lambda x: cleaning_repeating_char(x))\n",
        "df[\"Processed_Tweets\"]= df[\"Processed_Tweets\"].apply(lambda x: cleaning_email(x))\n",
        "df[\"Processed_Tweets\"]= df[\"Processed_Tweets\"].apply(lambda x: cleaning_URLs(x))\n",
        "df[\"Processed_Tweets\"] = df[\"Processed_Tweets\"].apply(lambda x: cleaning_numbers(x))\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "df[\"Processed_Tweets\"]  = df[\"Processed_Tweets\"] .apply(tokenizer.tokenize)\n",
        "df[\"Processed_Tweets\"] =df[\"Processed_Tweets\"] .apply(lambda x: stemming_on_text(x))\n",
        "\n",
        "df[\"Processed_Tweets\"]= df[\"Processed_Tweets\"].apply(lambda x: lemmatizer_on_text(x))\n",
        "\n",
        "\n",
        "df[\"Processed_Tweets\"].tail()\n",
        "df[\"Processed_Tweets\"] .head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZxkitOoEOmz",
        "outputId": "eed8879a-dd79-43df-98e9-dfc1afb70c16"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                  [wow, loved, place]\n",
              "1                                         [crust, god]\n",
              "2                              [tasty, texture, nasty]\n",
              "3    [stoped, late, may, bank, holiday, rick, steve...\n",
              "4                     [selection, menu, great, prices]\n",
              "Name: Processed_Tweets, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.Processed_Tweets\n",
        "y=df.label"
      ],
      "metadata": {
        "id": "Bm24tDUyFjIp"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 500\n",
        "tok = Tokenizer(num_words=2000)\n",
        "tok.fit_on_texts(X)\n",
        "sequences = tok.texts_to_sequences(X)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "IOEdFnO-FrQd"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivUPdN4PF1D6",
        "outputId": "d0650584-97c2-4535-b760-49f4ccf66b1f"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(sequences_matrix, y, test_size=0.3, random_state=2)"
      ],
      "metadata": {
        "id": "7AmKeOvTF4Cq"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorflow_based_model(): #Defined tensorflow_based_model function for training tenforflow based model\n",
        "    inputs = Input(name='inputs',shape=[max_len])#step1\n",
        "    layer = Embedding(2000,50,input_length=max_len)(inputs) #step2\n",
        "    layer = LSTM(64)(layer) #step3\n",
        "    layer = Dense(256,name='FC1')(layer) #step4\n",
        "    layer = Activation('relu')(layer) # step5\n",
        "    layer = Dropout(0.5)(layer) # step6\n",
        "    layer = Dense(1,name='out_layer')(layer) #step4 again but this time its giving only one output as because we need to classify the tweet as positive or negative\n",
        "    layer = Activation('sigmoid')(layer) #step5 but this time activation function is sigmoid for only one output.\n",
        "    model = Model(inputs=inputs,outputs=layer) #here we are getting the final output value in the model for classification\n",
        "    return model #function returning the value when we call it"
      ],
      "metadata": {
        "id": "iTWam0hsF6_M"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tensorflow_based_model() # here we are calling the function of created model\n",
        "model.compile(loss='binary_crossentropy',optimizer=\"Adam\",metrics=['accuracy'])  "
      ],
      "metadata": {
        "id": "JW0BRFwRF8m9"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train,Y_train,batch_size=80,epochs=20, validation_split=0.1)# here we are starting the training of model by feeding the training data\n",
        "print('Training finished !!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRmnRQZVF_wr",
        "outputId": "837754b6-d508-4733-f5a7-113333930bc4"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "7/7 [==============================] - 5s 742ms/step - loss: 0.9390 - accuracy: 0.4921 - val_loss: 0.7096 - val_accuracy: 0.5571\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 4s 637ms/step - loss: 0.7347 - accuracy: 0.5254 - val_loss: 0.7176 - val_accuracy: 0.4857\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 5s 643ms/step - loss: 0.6786 - accuracy: 0.5413 - val_loss: 0.7024 - val_accuracy: 0.5571\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 5s 641ms/step - loss: 0.7277 - accuracy: 0.4937 - val_loss: 0.7094 - val_accuracy: 0.5571\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 5s 635ms/step - loss: 0.7095 - accuracy: 0.4937 - val_loss: 0.6879 - val_accuracy: 0.5571\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 4s 634ms/step - loss: 0.6611 - accuracy: 0.5190 - val_loss: 0.6657 - val_accuracy: 0.6000\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 5s 770ms/step - loss: 0.6164 - accuracy: 0.6460 - val_loss: 0.6564 - val_accuracy: 0.6143\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 5s 649ms/step - loss: 0.5841 - accuracy: 0.7460 - val_loss: 0.6546 - val_accuracy: 0.5857\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 5s 732ms/step - loss: 0.5516 - accuracy: 0.7794 - val_loss: 0.6435 - val_accuracy: 0.6000\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 5s 647ms/step - loss: 0.5064 - accuracy: 0.8095 - val_loss: 0.6214 - val_accuracy: 0.6286\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 5s 666ms/step - loss: 0.4470 - accuracy: 0.8587 - val_loss: 0.5979 - val_accuracy: 0.6286\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 6s 849ms/step - loss: 0.3905 - accuracy: 0.8556 - val_loss: 0.5761 - val_accuracy: 0.6429\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 5s 650ms/step - loss: 0.2984 - accuracy: 0.8984 - val_loss: 0.5526 - val_accuracy: 0.7000\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 5s 637ms/step - loss: 0.2314 - accuracy: 0.9238 - val_loss: 0.5622 - val_accuracy: 0.7286\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 5s 641ms/step - loss: 0.1691 - accuracy: 0.9619 - val_loss: 0.9089 - val_accuracy: 0.7429\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 5s 638ms/step - loss: 0.1134 - accuracy: 0.9730 - val_loss: 1.0755 - val_accuracy: 0.7429\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 4s 633ms/step - loss: 0.0814 - accuracy: 0.9778 - val_loss: 1.3967 - val_accuracy: 0.7429\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 5s 652ms/step - loss: 0.0619 - accuracy: 0.9794 - val_loss: 1.3998 - val_accuracy: 0.7571\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 5s 642ms/step - loss: 0.0561 - accuracy: 0.9825 - val_loss: 1.4143 - val_accuracy: 0.7571\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 5s 643ms/step - loss: 0.0445 - accuracy: 0.9841 - val_loss: 1.4338 - val_accuracy: 0.7714\n",
            "Training finished !!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accr1 = model.evaluate(X_test,Y_test) #we are starting to test the model here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kS22EMPGMfn",
        "outputId": "6ec38360-69c4-4096-f83e-b5724dd75c07"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 67ms/step - loss: 1.2899 - accuracy: 0.7767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set\\n  Accuracy: {:0.2f}'.format(accr1[1])) #the accuracy of the model on test data is given below"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnQkOjlAGSWl",
        "outputId": "3a524b32-973b-4d8e-8672-d73f7d9ba856"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set\n",
            "  Accuracy: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test) #getting predictions on the trained model\n",
        "y_pred = (y_pred > 0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C8ckrMwGVEP",
        "outputId": "cbd23f57-ae35-44e4-c6bb-9293e741c9c3"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 103ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n')\n",
        "print(\"confusion matrix\")\n",
        "print('\\n')\n",
        "CR=confusion_matrix(Y_test, y_pred)\n",
        "print(CR)\n",
        "print('\\n')\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=CR,figsize=(10, 10),\n",
        "                                show_absolute=True,\n",
        "                                show_normed=True,\n",
        "                                colorbar=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYUslHqvGYW4",
        "outputId": "2e8465d6-65e3-4588-9488-9c1c32a3a0e2"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "confusion matrix\n",
            "\n",
            "\n",
            "[[115  36]\n",
            " [ 31 118]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}